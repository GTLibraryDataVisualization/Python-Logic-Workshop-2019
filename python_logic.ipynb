{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Logic\n",
    "\n",
    "In the first workshop, we covered the basics of Python. In this workshop, we will build upon that knowledge and explore one of Python's strengths of manipulating data by using tools Python provides to build a simple file parsing program. The file parser will read in a file, parse the data, and write out our cleaned data as a CSV file, as well as to print some statistics about our program's runtime to console.\n",
    "\n",
    "Before we get started, theres a few areas of python to discuss\n",
    "\n",
    "### Packages\n",
    "\n",
    "One of the biggest strengths of python is the number of packages that have been written for it. **Packages** are tools that other people have written that can be used in our own code. Packages are very helpful because they help you write code more efficiently and consisely since you can use functionality that is already written.\n",
    "\n",
    "Packages are easy to install, if you're using Anaconda, most of the popular packages are already there for you to use. If you installed python from the official site, then we need to use **pip**, python's official package manager to install them accessed from the terminal. (not a python file or the python interactive prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install numpy\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more informations on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to tell python that we want to use specific packages in our program. Depending on how much of a package we want to use, there are a few ways to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy # so we can use numpy in our program\n",
    "\n",
    "import numpy as np # now we can refer to numpy as np \n",
    "\n",
    "from numpy import * # brings in every numpy function for us to use, or replace * with the specific function you want to import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we want to use our own programs as packages we can do that, either by putting the file in the same folder and using **import 'filename'** (without .py). If its in a different folder, we tell python the RELATIVE path to the file. So for example hello.py in the same folder would be imported with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f81fb083bdeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hello'"
     ]
    }
   ],
   "source": [
    "import hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or if its in a different folder we would specify the location using '..' to go up a folder and / to go in a folder. For example, to go up two folders and into a folder called packages we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-c1d6e7036059>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-c1d6e7036059>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import ../../packages/hello\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import ../../packages/hello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, why are packages important? They can help reduce the complexity of the code you write by utilizing code that is already written. They can also help make code easier to read. For example, Numpy is a popular package used for scientific computing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\_\\_main\\_\\_\n",
    "\n",
    "Next, we will go over the \"main\" function. When writing code, we want to organize it in a way that is readable and that makes sense. Python reads a file from top to bottom. What this means is that if we have a function that calls another function, we want to make sure the function that is called is defined before the function that is making the call. It is good practice to group code into different functions based on what the code does. Then, we can define a function called main() which will be used to contain code that we actually want to run.  \n",
    "\n",
    "Programming languages run code in whats called a \"main\" function. Python considers all code not in a function definition to be part of the main funcion.\n",
    "\n",
    "This means, Python runs code from first line to last line, following standard logic flow, and we need to define a function before, or above, where we first use (or call) it.\n",
    "\n",
    "So, when we import a package, python will take the line **import 'package'** and RUN the files it looks at.\n",
    "\n",
    "If its just defining funcions this is okay, but sometimes we want packages to do things IF AND ONLY IF its the file we call in terminal with the command **python hello.py**\n",
    "\n",
    "To do this we use a special variable python has called **\\_\\_name\\_\\_** (with two underscores before and after)\n",
    "If its the file we ran, the **\\_\\_name\\_\\_** variable will be **\\_\\_main\\_\\_**\n",
    "otherwise it will be the name of the imported package (eg. **\\_\\_hello\\_\\_**)\n",
    "\n",
    "This means we can write the code below (in hello.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1():\n",
    "    break\n",
    "\n",
    "def func2():\n",
    "    break\n",
    "\n",
    "def main():\n",
    "    func1()\n",
    "    func2()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what happens here is python sees main, but because we're only defining the function it doesn't run it. If we used the terminal to call hello.py, it then sees that the **\\_\\_name\\_\\_** variable is **\\_\\_main\\_\\_** and runs the code in **main()**, if we imported it with **import hello**, the **\\_\\_main\\_\\_** variable will be **\\_\\_hello\\_\\_** and code in **main()** wont run.\n",
    "\n",
    "So lets put together some basic code that we'll need for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    break\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the skeleton of our program written, with the numpy and timer (more on that later) packages imported, we can start writing the body of our code.\n",
    "Again, it is important to understand the way logic flows in Python so that when you are writing code, you can think about how to organize your code for readability.\n",
    "\n",
    "\n",
    "### Reading from files\n",
    "\n",
    "Data can stored in a number of different file formats such as a text file or csv file. Python has the ability to look into a file and extract information from it so that we are able to work with the data. This is called reading from a file. For our project, we will be reading into the example_data.txt file  \n",
    "\n",
    "The **open()** function takes in two string parameters: a file and a mode (ex: \"r\" for 'read' or \"w\" for 'write) and returns a file object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"..files/example_data.txt\",\"r\") # opens example_data.txt in read mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASIDE: we can name variables almost anything we want following the few rules that exist. **file** already exists as a keywork in python, so we need to use something else. Popular variable names include **f** for \"file\" or **fp** for \"file-pointer\".\n",
    "\n",
    "when we are done using our file we need to call **close()**. There are a lot of problems that can occur if we don't close a file, but they're a bit too technical for our purposes. For now, just remember to call **close()** when you're done with a file.\n",
    "\n",
    "Once we have our file opened in read mode, we want to get data from our file, which we can do in a few ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file.read() # this reads in the ENTIRE file and returns the contents as a string\n",
    "# this works for our sample file, but will fill up our computers memory for really big files\n",
    "\n",
    "data = file.read(100) # reads ONLY the first 100 characters of a file, returns a string\n",
    "\n",
    "line = file.readline() # this reads the file line by line, returning a string\n",
    "# this can be used if our file is large and we want to look at a line one at a time\n",
    "\n",
    "# if we know our file is short enough...\n",
    "lines = file.readlines() # reads in ALL times, where each line is an entry in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in a file, lines will end with an invisible newline character (**\\\\n**), **readline()** will look at one line at a time (as a string) stopping each line at a new line character.\n",
    "\n",
    "Since we're only looking at one line at a time, this reduces memory usage significantly.\n",
    "\n",
    "Let's edit our program, we'll pretend we're using a large file and need to worry about memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    fp = open(\"..files/example_data.txt\", \"r\")\n",
    "    line = fp.readline()\n",
    "    print(line)\n",
    "    while line:\n",
    "        line = fp.readline()\n",
    "        print(line)\n",
    "    fp.close()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a more elegant solution using the **with** statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿# a python comment in a txt file!?\n",
      "\n",
      "data: not-a number, gpa: 3.2, credits: 135, semesters: 9\n",
      "\n",
      "credits:132, gpa : 3.8, semesters: 8\n",
      "\n",
      "gpa : 4.0, credits: 73, filler, semesters: 3\n",
      "\n",
      "gpa:2.9, filler, credits :56, semesters: 4\n",
      "\n",
      "credits : 90, garbage, gpa: 3.7, semesters: 7\n",
      "\n",
      "gpa:3.2, semesters: 7, credits :113,\n",
      "\n",
      "! another random character?\n",
      "\n",
      "5 + 137 = 142\n",
      "\n",
      "gpa: 3.7, credits: 15, semesters: 1\n",
      "\n",
      "and more noise\n",
      "\n",
      "　\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    with open(\"example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            print(line)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does the exact same thing, but is more concise, easier to read, and will automatically close the file when we leave the with statement. Its the best way to read a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Strings\n",
    "\n",
    "Now that we can access our file, we can start parsing and cleaning the contents in the file to grab only the data that we want to look at. Let's take a moment to try and understand how our data is formatted.\n",
    "\n",
    "If you look at the file example_data.txt youll notice that in general it's formatted as \"word\" : \"number\"\n",
    "\n",
    "but there's a few lines spread out that don't follow this pattern. That's junk data that we're going to need to deal with as we look at lines.\n",
    "\n",
    "*I will make a guarantee, so that we don't need to worry about it, that every valid row will have all the same words* *before colons (gpa, credits, semesters).*\n",
    "\n",
    "Python has alot of tools for us to work with, but we'll focus on just a few. If you want to read up on them, documentation is availabe: https://docs.python.org/3.7/library/stdtypes.html\n",
    "and https://docs.python.org/3.7/library/string.html\n",
    "Documentation is not something to memorize, it is used for reference.\n",
    "feel free to \"control + f\" and search for these in the documentation to learn more about them.\n",
    "\n",
    "The functions/constants we'll be focusing on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.lower() # returns a copy of the string with all lowercase characters\n",
    "str.strip() # removes all spaces (or other characters) from a string\n",
    "str.split() # splits the string on the characters we ask for, returns an array\n",
    "str.isdigit() # returns True if str is made of only numbers\n",
    "str.isalpha() # returns True if str is made of only letters\n",
    "\n",
    "str.ascii_letters # constant; is a string of all ascii letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASIDE: for more complex string manipulation there are \"regular expressions\". Those are much more powerful but are extremely difficult to use. They were designed to parse natural language, how we write and speak in natural english, rather than formatted data and is thus beyond the scope of this workshop.\n",
    "\n",
    "so, lets deal with the easiest lines first and remove lines that don't start with a letter and don't contain a colon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if line[0] is in string.ascii_letters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**string.ascii_letters** requires the string package, so lets import that too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets make sure our line has the general formatting of what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \":\" is in line:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So these statements will get rid of our junk lines. We can combine our two if statements together as well, so lets do that as we modify our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: not-a number, gpa: 3.2, credits: 135, semesters: 9\n",
      "\n",
      "credits:132, gpa : 3.8, semesters: 8\n",
      "\n",
      "gpa : 4.0, credits: 73, filler, semesters: 3\n",
      "\n",
      "gpa:2.9, filler, credits :56, semesters: 4\n",
      "\n",
      "credits : 90, garbage, gpa: 3.7, semesters: 7\n",
      "\n",
      "gpa:3.2, semesters: 7, credits :113,\n",
      "\n",
      "gpa: 3.7, credits: 15, semesters: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def main():\n",
    "    with open(\"example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            if line[0] in string.ascii_letters and ':' in line:\n",
    "                print(line)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, lets get rid of whitespace and seperate our string so we can get data out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = line.lower() # makes everything lowercase\n",
    "line = line.strip() # removes whitespace\n",
    "line = line.split(',') # splits the line at the ,'s into a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets add this to our program, in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data: not-a number', ' gpa: 3.2', ' credits: 135', ' semesters: 9']\n",
      "['credits:132', ' gpa : 3.8', ' semesters: 8']\n",
      "['gpa : 4.0', ' credits: 73', ' filler', ' semesters: 3']\n",
      "['gpa:2.9', ' filler', ' credits :56', ' semesters: 4']\n",
      "['credits : 90', ' garbage', ' gpa: 3.7', ' semesters: 7']\n",
      "['gpa:3.2', ' semesters: 7', ' credits :113', '']\n",
      "['gpa: 3.7', ' credits: 15', ' semesters: 1']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def main():\n",
    "    with open(\"example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            if line[0] in string.ascii_letters and ':' in line:\n",
    "                line = line.lower().strip().split(',')\n",
    "                print(line)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the order of these functions is executed left to right, looking at what these functions do, as long as .split(',') is at the end, this will run, as .lower() and .strip() return strings while .split() returns a list.\n",
    "\n",
    "also, because we assigned this new output to line, we can no longer get the original line back as it was in the file.\n",
    "\n",
    "Currently line is a list, so \\[entry_1, entry_2, ... , entry_n\\]\n",
    "\n",
    "\n",
    "Lets continue to parse this, we want to make sure every entry has data in the format we want \"word\" : \"number\" which means our conditions are is if : is in the entry, if the left is a word, and the right is a digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in line:\n",
    "    if \":\" in entry:\n",
    "        data = entry.split(':')\n",
    "        if data[0].isalpha() and data[1].isdigit():\n",
    "            print(data[0] + \" \" + data[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets add this to our program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credits 132\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def main():\n",
    "    with open(\"example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            if line[0] in string.ascii_letters and ':' in line:\n",
    "                line = line.lower().strip().split(',')\n",
    "                for entry in line:\n",
    "                    if \":\" in entry:\n",
    "                        data = entry.split(':')\n",
    "                        if data[0].isalpha() and data[1].isdigit():\n",
    "                            print(data[0] + \" \" + data[1])\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait! we are checking for \":\" in two places, we don't need to do that.\n",
    "\n",
    "Lets think about it, if \":\" is in our line theres no guarantee that every entry will have one, but if every entry has a \":\" that line valid line will to. So we can simplify our code and remove the redundancy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credits 132\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def main():\n",
    "    with open(\"example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            if line[0] in string.ascii_letters:\n",
    "                line = line.lower().strip().split(',')\n",
    "                for entry in line:\n",
    "                    if \":\" in entry:\n",
    "                        data = entry.split(':')\n",
    "                        if data[0].isalpha() and data[1].isdigit():\n",
    "                            print(data[0] + \" \" + data[1])\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we said we wanted to make a CSV of our data. it was presented with \":\", so the best way for us to store the data in our program is with a dictionary, data\\[0\\] is our key and data\\[1\\] is our value.\n",
    "\n",
    "we're going to need to have one for every line as well, so lets make a list to store our dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(\"..files/example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            data_dict = dict()\n",
    "            if line[0] in string.ascii_letters:\n",
    "                line = line.lower().strip().split(',')\n",
    "                for entry in line:\n",
    "                    if ':' in entry:\n",
    "                        data = entry.split(':')\n",
    "                        if data[0].isalpha() and data[1].isdigit():\n",
    "                            data_dict[data[0]] = data[1]\n",
    "                            \n",
    "                data_dicts.append(data_dict)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we have seen, Python has many tools that help us parse and clean data so that we can format data into a readable format. There is plenty of documentation available online of the many tools in Python that you can use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After manipulating data and getting the data into the format that we want, we can now use Python to transfer this data into another file. This is called writing to a file.\n",
    "\n",
    "Writing to files is similar to reading from them. First we need to open a file in write mode, so use the **open()** function, but with **\"w\"** instead of **\"r\"**.\n",
    "\n",
    "If the file we tell Python to write to doesnt exist, it will create a new file, if it does exist, it will write over the old one, deleting all data in it previously. If we don't want to clear the file and instead append to it, we can use the append mode with **\"a\"** instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"..files/example_parsed.csv\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add this to our code, but use that same **with** keyword as before\n",
    "since by this point we're done with our first open, we can use **fp** again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(\"..files/example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            data_dict = dict()\n",
    "            if line[0] is in string.ascii_letters:\n",
    "                line = line.lower().strip().split(',')\n",
    "                for entry in line:\n",
    "                    if ':' in entry:\n",
    "                        data = entry.split(':')\n",
    "                        if data[0].isalpha() and data[1].isdigit():\n",
    "                            data_dict[data[0]] = data[1]\n",
    "            if len(data_dicts) != 0:\n",
    "                data_dicts.append(data_dict)\n",
    "            \n",
    "    with open(\"..files/example_parsed.csv\", \"w\") as fp:\n",
    "        break\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use the **file.write()** function to write to a file. **file.write()** does not add newlines, but we can manually add them when we want with the newline character **\\n**. for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_var = \"Andrew\"\n",
    "with open (\"hello.txt\", \"w\") as fp:\n",
    "    fp.write(\"hello, my name is \" + name_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets think about what we need to do to write the data we've parsed from our file properly.\n",
    "We have a list of dictionaries where each dictionary has three entries; one for gpa, semester, and credits\n",
    "\n",
    "We need to make one line for each dictionary in our list **data_dicts**. The first line, or the header of our file, should be the keys (gpa, semester, credits), then we need to traverse the values in the dictionary, and write them to the line, comma's seperating all of them EXCEPT the last. We also do not want a comma at the end of the line. In short we want *\"a_val, b_val, c_val, d_val, e_val, ... , n_val\"*\n",
    "\n",
    "Lets modify our program first to write the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(\"..files/example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            data_dict = dict()\n",
    "            if line[0] is in string.ascii_letters:\n",
    "                line = line.lower().strip().split(',')\n",
    "                for entry in line:\n",
    "                    if ':' in entry:\n",
    "                        data = entry.split(':')\n",
    "                        if data[0].isalpha() and data[1].isdigit():\n",
    "                            data_dict[data[0]] = data[1]\n",
    "            if len(data_dicts) != 0:\n",
    "                data_dicts.append(data_dict)\n",
    "            \n",
    "    with open(\"..files/example_parsed.csv\", \"w\") as fp:\n",
    "        for index, key in enumerate(data_dicts[0].keys()):\n",
    "            if index < len(data_dicts[0]) - 1:        #determine if key is at the last index\n",
    "                fp.write(key + \", \")\n",
    "            else:\n",
    "                fp.write(key + \"\\n\")\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the function **enumerate()** this lets us traverse a list, so that we can get TWO variables, the value of the list at our current location, and the index of the list of our current location. This is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(data_dicts[0].keys())):\n",
    "    print(data_dicts[0].keys()[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using **enumerate()** is much easier to read.\n",
    "\n",
    "We added \",\" between each word and a newline character \"\\n\" at the end of the line as well. \n",
    "\n",
    "now we want to go through the values of the dictionary and print them out seperated by commas for each line, so lets do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(\"..files/example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            data_dict = dict()\n",
    "            if line[0] is in string.ascii_letters:\n",
    "                line = line.lower().strip().split(',')\n",
    "                for entry in line:\n",
    "                    if ':' in entry:\n",
    "                        data = entry.split(':')\n",
    "                        if data[0].isalpha() and data[1].isdigit():\n",
    "                            data_dict[data[0]] = data[1]\n",
    "            if len(data_dicts) != 0:\n",
    "                data_dicts.append(data_dict)\n",
    "            \n",
    "    with open(\"..files/example_parsed.csv\", \"w\") as fp:\n",
    "        for index, key in enumerate(data_dicts[0].keys()):\n",
    "            if index < len(data_dicts[0] - 1):\n",
    "                fp.write(key + \", \")\n",
    "            else:\n",
    "                fp.write(key + \"\\n\")\n",
    "        for data_dict in data_dicts:\n",
    "            for index, value in enumerate(data_dict.values()):\n",
    "                if index < len(data_dict[0] - 1):\n",
    "                    fp.write(value + \", \")\n",
    "                else:\n",
    "                    fp.write(value + \"\\n\")\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was almost the same thing as what we did to write the keys, except were looking at **dict.values()** and doing it for each dictionary in our list.\n",
    "\n",
    "ASIDE: Dictionaries are UNORDERED, however, python has a specific way to order the key : value pairs to store them in memory, and when we request them, we will always get it back in this order. So calling data_dict.values() will guarantee a specific order to our unordered data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While reading like this is in fact correct, we chose to write to a csv. Because a proper CSV file has a guaranteed format for our data, it's easy to make a tool for us to read and write that we can use instead of re-writing it over and over again.\n",
    "\n",
    "Python has already done this for us, so we dont even need to write the tool, we can just use it, its in the preinstalled **csv** package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "\n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(\"..files/example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            data_dict = dict()\n",
    "            if line[0] is in string.ascii_letters:\n",
    "                line = line.lower().strip().split(',')\n",
    "                for entry in line:\n",
    "                    if ':' in entry:\n",
    "                        data = entry.split(':')\n",
    "                        if data[0].isalpha() and data[1].isdigit():\n",
    "                            data_dict[data[0]] = data[1]\n",
    "            if len(data_dicts) != 0:\n",
    "                data_dicts.append(data_dict)\n",
    "            \n",
    "    with open(\"..files/example_parsed.csv\", \"w\") as fp:\n",
    "        writer = csv.DictWriter(fp, data_dicts[0].keys()) #parameters: file and fieldnames\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_dicts)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats it! A lot of programming is wondering if a language can do this or that beforehand and doing a quick google search or search through the documentation to check and to learn how. You'll learn the full capabilities of a language by using and exploring it yourself, so practice, practice, practice! lets quickly see what these functions do here: https://docs.python.org/3.6/library/csv.html\n",
    "\n",
    "At this point theres a small problem with our code, a problem I'll leave to you to fix. If we have a massive file we're going to use a massive amount of memory since we're storing all of it in a list of dictionaries before we even begin to write.\n",
    "\n",
    "Try rewriting the above code so that it writes to the file as it reads it in.\n",
    "I've included one of my solutions in combined.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning our code\n",
    "\n",
    "With the current state of our code, our **main()** function is doing alot, its reading in a file, parsing it, and writing to a file(). So lets break the parsing part into a new fuction called **parse()**. We're going to want to pass in a line (so it can exist through multiple calls), and have it return a dictionary that we can then append to our **dict_list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "\n",
    "def parse(list):\n",
    "    return data_dict\n",
    "\n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(\"..files/example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            data_dict = dict()\n",
    "            if line[0] is in string.ascii_letters:\n",
    "                line = line.lower().strip().split(',')\n",
    "                for entry in line:\n",
    "                    if ':' in entry:\n",
    "                        data = entry.split(':')\n",
    "                        if data[0].isalpha() and data[1].isdigit():\n",
    "                            data_dict[data[0]] = data[1]\n",
    "            if len(data_dicts) != 0:\n",
    "                data_dicts.append(data_dict)\n",
    "            \n",
    "    with open(\"..files/example_parsed.csv\", \"w\") as fp:\n",
    "        writer = csv.DictWriter(fp, data_dicts[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_dicts)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the code to do this already exists, starting at **data_dict = dict()** and adding a return statement instead of the **data_dicts.append(data_dict)** line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "\n",
    "def parse(line):\n",
    "    data_dict = dict()\n",
    "    if line[0] is in string.ascii_letters:\n",
    "        line = line.lower().strip().split(',')\n",
    "        for entry in line:\n",
    "            if ':' in entry:\n",
    "                data = entry.split(':')\n",
    "                if data[0].isalpha() and data[1].isdigit():\n",
    "                    data_dict[data[0]] = data[1]\n",
    "    if len(data_dicts) != 0:\n",
    "        return data_dict\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "\n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(\"..files/example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "        \n",
    "           data_dict = parse(line)\n",
    "           data_dicts.append(data_dict) \n",
    "            \n",
    "    with open(\"..files/example_parsed.csv\", \"w\") as fp:\n",
    "        writer = csv.DictWriter(fp, data_dicts[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_dicts)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can compress this a bit further without making it any more difficult to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "\n",
    "def parse(line):\n",
    "    data_dict = dict()\n",
    "    if line[0] is in string.ascii_letters:\n",
    "        line = line.lower().strip().split(',')\n",
    "        for entry in line:\n",
    "            if ':' in entry:\n",
    "                data = entry.split(':')\n",
    "                if data[0].isalpha() and data[1].isdigit():\n",
    "                    data_dict[data[0]] = data[1]\n",
    "    if len(data_dicts) != 0:\n",
    "        return data_dict\n",
    "        \n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(\"..files/example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "           data_dicts.append(parse(line)) # we can combine the two statements for this\n",
    "            \n",
    "    with open(\"..files/example_parsed.csv\", \"w\") as fp:\n",
    "        writer = csv.DictWriter(fp, data_dicts[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_dicts)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit more manageable to read. our main function reads in a file and writes out to a file.\n",
    "It also calls a parse function to parse our line. We don't need to care how the parsing works as long as what it returns is in the format we expect (a dictionary).\n",
    "\n",
    "A bonus of this is now if we want to use the same parsing function in a different program, we can just import the file and call **parse()**, and because **\\_\\_name\\_\\_** of the file won't be **\\_\\_main\\_\\_** the function **main()** wont run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sometimes its useful to know how long a program or function takes to run, so lets quickly put together a timer.\n",
    "\n",
    "to do this we need use the **time()** function in the time package\n",
    "\n",
    "**time()** returns the time in seconds (as a decimal) since the epoch, or 00:00 on Thurdsay, Janurary 1st, 1970, so we can do basic arithmetic to determine the number of seconds, minutes, hours, or days elapsed at any two points in time.\n",
    "\n",
    "ASIDE: because values in programming take up memory, they eventually hit a maximum value. Once the number of seconds from the epoch to a current moment in time occurs, various changes will have to made to Python and computers to adjust for this. That means currently, Python's time function will break sometime in 2038 (on Unix systems).\n",
    "\n",
    "so to create a basic timer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "... # our code\n",
    "end = time.time()\n",
    "elapsed = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets add that to our program to measure the time it takes to run the code *if and only if* we run the file as where **\\_\\_name\\_\\_** is **\\_\\_main\\_\\_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import time\n",
    "\n",
    "def parse(line):\n",
    "    data_dict = dict()\n",
    "    if line[0] is in string.ascii_letters:\n",
    "        line = line.lower().strip().split(',')\n",
    "        for entry in line:\n",
    "            if ':' in entry:\n",
    "                data = entry.split(':')\n",
    "                if data[0].isalpha() and data[1].isdigit():\n",
    "                    data_dict[data[0]] = data[1]\n",
    "    if len(data_dicts) != 0:\n",
    "        return data_dict\n",
    "        \n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(\"..files/example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "           data_dicts.append(parse(line))\n",
    "            \n",
    "    with open(\"..files/example_parsed.csv\", \"w\") as fp:\n",
    "        writer = csv.DictWriter(fp, data_dicts[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_dicts)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    main()\n",
    "    elapsed = time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Formatting\n",
    "\n",
    "lets print this out to terminal, in the format \"program ran in \\_\\_\\_\\_\\_ minutes and \\_\\_\\_\\_\\_ seconds\"\n",
    "we can do this with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_min = elapsed // 60\n",
    "elapsed_sec = elapsed % 60\n",
    "print(\"program ran in \" + str(elapsed_min) + \" minutes and \" + str(elapsed_sec) \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theres a slightly cleaner way to do this using **str.format()**\n",
    "to say the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"program ran in {} minutes and {} seconds\".format(elapsed_min, elapsed_sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a way to format strings in python3, its much easier to read than before. It automatically casts our values to strings as well! We can compress this further with something called *fstrings*, but for now lets focus on readability instead of brevity.\n",
    "\n",
    "the **{}** will be replaced with what we pass in to **str.format()** in the order we pass it in, so elapsed_min fills in the first **{}** and **elapsed_sec** fills in the second **{}**\n",
    "\n",
    "lets make one change such that the number of seconds gets printed to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"program ran in {} minutes and {:.3f} seconds\".format(elapsed_min, elapsed_sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the .3f means \"after the decimal, round the number to three places in a floating point number format\n",
    "\n",
    "There are alot of different combinations, and the best way to learn them is googling how and to experimenting yourself. For a full list of various formatting options for strings ive included the link below\n",
    "\n",
    "https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting\n",
    "\n",
    "Lets add this to our program so it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import time\n",
    "\n",
    "def parse(line):\n",
    "    data_dict = dict()\n",
    "    if line[0] is in string.ascii_letters:\n",
    "        line = line.lower().strip().split(',')\n",
    "        for entry in line:\n",
    "            if ':' in entry:\n",
    "                data = entry.split(':')\n",
    "                if data[0].isalpha() and data[1].isdigit():\n",
    "                    data_dict[data[0]] = data[1]\n",
    "    if len(data_dicts) != 0:\n",
    "        return data_dict\n",
    "        \n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(\"..files/example_data.txt\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "           data_dicts.append(parse(line))\n",
    "            \n",
    "    with open(\"..files/example_parsed.csv\", \"w\") as fp:\n",
    "        writer = csv.DictWriter(fp, data_dicts[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_dicts)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    main()\n",
    "    elapsed = time.time() - start\n",
    "    elapsed_min = elapsed // 60 # integer division, will always guarentee a whole number, rounded DOWN\n",
    "    elapsed_sec = elapsed % 60 # modulous, will give us the remainder of elapsed / 60\n",
    "    print(\"program ran in {} minutes and {:.3f} seconds\".format(elapsed_min, elapsed_sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Line Arguments\n",
    "\n",
    "There is one last problem with our code we should worry about fixing. Right now, the file we want to read in and the file we want to read out, are hard coded in the middle of our program, if this was a longer file, it would be hard to find, so lets put some constants at the top of our program to make this easier.\n",
    "\n",
    "Constants in python are actually just variables, but we tell the programmer that we dont want to value to change by using all capital letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import time\n",
    "\n",
    "# Consants\n",
    "INPUT = \"..files/example_data.txt\"\n",
    "OUTPUT = \"..files/example_parsed.csv\"\n",
    "\n",
    "def parse(line):\n",
    "    data_dict = dict()\n",
    "    if line[0] is in string.ascii_letters:\n",
    "        line = line.lower().strip().split(',')\n",
    "        for entry in line:\n",
    "            if ':' in entry:\n",
    "                data = entry.split(':')\n",
    "                if data[0].isalpha() and data[1].isdigit():\n",
    "                    data_dict[data[0]] = data[1]\n",
    "    if len(data_dicts) != 0:\n",
    "        return data_dict\n",
    "        \n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(INPUT, \"r\") as fp: # and we replace the string with our variable\n",
    "        for line in fp:\n",
    "           data_dicts.append(parse(line))\n",
    "            \n",
    "    with open(OUTPUT, \"w\") as fp: # here too\n",
    "        writer = csv.DictWriter(fp, data_dicts[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_dicts)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    main()\n",
    "    elapsed = time.time() - start\n",
    "    elapsed_min = elapsed // 60\n",
    "    elapsed_sec = elapsed % 60\n",
    "    print(\"program ran in {} minutes and {:.3f} seconds\".format(elapsed_min, elapsed_sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its easy to change the values in our code! If we only intend to use this on the same file in the same relative location thats okay, but we still have to actually open the program to edit this should that change. We want this to be a bit more adaptable using **command line arguments**. to use them we need the *sys* module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Consants\n",
    "INPUT = \"..files/example_data.txt\"\n",
    "OUTPUT = \"..files/example_parsed.csv\"\n",
    "\n",
    "def parse(line):\n",
    "    data_dict = dict()\n",
    "    if line[0] is in string.ascii_letters:\n",
    "        line = line.lower().strip().split(',')\n",
    "        for entry in line:\n",
    "            if ':' in entry:\n",
    "                data = entry.split(':')\n",
    "                if data[0].isalpha() and data[1].isdigit():\n",
    "                    data_dict[data[0]] = data[1]\n",
    "    if len(data_dicts) != 0:\n",
    "        return data_dict\n",
    "        \n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(INPUT, \"r\") as fp:\n",
    "        for line in fp:\n",
    "           data_dicts.append(parse(line))\n",
    "            \n",
    "    with open(OUTPUT, \"w\") as fp:\n",
    "        writer = csv.DictWriter(fp, data_dicts[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_dicts)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    main()\n",
    "    elapsed = time.time() - start\n",
    "    elapsed_min = elapsed // 60\n",
    "    elapsed_sec = elapsed % 60\n",
    "    print(\"program ran in {} minutes and {:.3f} seconds\".format(elapsed_min, elapsed_sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is a good time to notice, the order I've been importing is alphabetical. There is no rule that this needs to be done so, but it makes it easier to read. in general I recommend:\n",
    "\n",
    "- import ___ and import ___ as where ___ is sorted alphabetically\n",
    "- from ___ import ___\n",
    "\n",
    "as the order to write your import statements. (readability is important!)\n",
    "\n",
    "At this point in time we can get arguments from command line, python will expect commands in the form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python program.py arg1 arg2 arg3 arg4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can access the arguments as we would an array. note that program.py is actually the argument at index 0, so we need to say **sys.argv\\[1\\]** to get arg1\n",
    "\n",
    "in our program lets give the constants the value of arg1 for **INPUT** and arg2 for **OUTPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Consants\n",
    "INPUT = str(sys.argv[1]) # assign the constants their values, and make them strings\n",
    "OUTPUT = str(sys.argv[2])\n",
    "\n",
    "def parse(line):\n",
    "    data_dict = dict()\n",
    "    if line[0] is in string.ascii_letters:\n",
    "        line = line.lower().strip().split(',')\n",
    "        for entry in line:\n",
    "            if ':' in entry:\n",
    "                data = entry.split(':')\n",
    "                if data[0].isalpha() and data[1].isdigit():\n",
    "                    data_dict[data[0]] = data[1]\n",
    "    if len(data_dicts) != 0:\n",
    "        return data_dict\n",
    "        \n",
    "def main():\n",
    "    data_dicts = list()\n",
    "    \n",
    "    with open(INPUT, \"r\") as fp:\n",
    "        for line in fp:\n",
    "           data_dicts.append(parse(line))\n",
    "            \n",
    "    with open(OUTPUT, \"w\") as fp:\n",
    "        writer = csv.DictWriter(fp, data_dicts[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_dicts)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    main()\n",
    "    elapsed = time.time() - start\n",
    "    elapsed_min = elapsed // 60\n",
    "    elapsed_sec = elapsed % 60\n",
    "    print(\"program ran in {} minutes and {:.3f} seconds\".format(elapsed_min, elapsed_sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we finally have a proper, well written program, lets run it! in the command line we navigate to the folder this file workshop_parser.py is saved in, then type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python workshop_parser.py ..files/example_data.txt ..files/example_parsed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when its done there should be new file called exapmle_parsed.csv in the \"files\" folder, example_data.txt remained untouched, and the runtime should be printed to the console. Check to make everything is working as intended. The final version of this program is avaialbe above or in the file **workshop_parser_FINAL.py**.\n",
    "\n",
    "ASIDE: Theres still a few quality of life improvement we can add the file, making sure the arguments called with our file follow an expected format and adding some documentation. None of these are necessary if we plan to keep the file small and for personal use only and is therefore outside the scope of this workshop. I've included an extra file with the additions I've discussed called **workshop_parser_FINAL_ASIDE.py**. If you wish to see these changes, take a look at that file.\n",
    "\n",
    "The first workshop covered the basics of python, this workshop worked on taking data to clean and present in a format we can easily work with for later. Now that we have data in the format we want, In the next workshop we'll be focusing on performing statistical analysis of our data and visuzalizing it with numpy and plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
